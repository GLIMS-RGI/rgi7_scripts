{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "super-stewart",
   "metadata": {},
   "source": [
    "# RGI-07: Region 14\n",
    "\n",
    "F. Maussion & S. Galos, June 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pressed-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from utils import mkdir\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-globe",
   "metadata": {},
   "source": [
    "### specify RGI-region and storage paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "portable-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of interest\n",
    "reg = 14\n",
    "\n",
    "# go down from rgi7_scripts/workflow\n",
    "data_dir = '../../rgi7_data/'\n",
    "\n",
    "# Level 2 GLIMS files\n",
    "l2_dir = os.path.join(data_dir, 'l2_sel_reg_tars')\n",
    "\n",
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_rgi7a'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_rgi7a_tar'))\n",
    "\n",
    "# RGI v6 file for comparison later \n",
    "rgi6_reg_file = os.path.join(data_dir, 'l0_RGIv6', '14_rgi60_SouthAsiaWest.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "guilty-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region is based on GAMDAM, use for comparison\n",
    "support_dir = os.path.join(data_dir, 'l0_support_data')\n",
    "gamdam_dir = os.path.join(support_dir, 'gamdam')\n",
    "\n",
    "# Region file to select from gamdam\n",
    "reg_file = os.path.join(data_dir, 'l0_regions', '00_rgi70_regions', '00_rgi70_O1Regions.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-boundary",
   "metadata": {},
   "source": [
    "### Load the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numeric-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read L2 files\n",
    "shp = gpd.read_file('tar://' + l2_dir + f'/RGI{reg:02d}.tar.gz/RGI{reg:02d}/RGI{reg:02d}.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-macro",
   "metadata": {},
   "source": [
    "### Apply selection criteria to create the RGI-07 data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fifty-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to get the data relevant for RGI07 and select by attributes\n",
    "RGI_ss = shp.loc[shp['analysts'] == 'Sakai, Akiko']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-personality",
   "metadata": {},
   "source": [
    "## Write out and tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entitled-backing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing...\n",
      "Taring...\n",
      "CompletedProcess(args=['tar', '-zcvf', '../../rgi7_data/l3_rgi7a_tar/RGI14.tar.gz', '-C', '../../rgi7_data/l3_rgi7a', 'RGI14'], returncode=0)\n"
     ]
    }
   ],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "RGI_ss.to_file(dd + f'RGI{reg:02d}.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-ceiling",
   "metadata": {},
   "source": [
    "## New RGI-file created - Check result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-orchestra",
   "metadata": {},
   "source": [
    "### load reference data (here GAMDAM original) to enable comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "buried-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify path to reference data set\n",
    "import zipfile\n",
    "import glob\n",
    "gam_files = glob.glob(gamdam_dir + '/*.zip')\n",
    "df_ref = []\n",
    "for gf in gam_files:\n",
    "    # Just to know the name of the file to open from zip\n",
    "    with zipfile.ZipFile(gf, \"r\") as z:\n",
    "        for f in z.filelist:\n",
    "            if '.shp' in f.filename:\n",
    "                fname = f.filename\n",
    "    df_ref.append(gpd.read_file('zip://' + gf + '/' + fname))\n",
    "\n",
    "df_ref = pd.concat(df_ref).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "falling-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate representative points for reference data\n",
    "ref_rp = df_ref.representative_point()\n",
    "\n",
    "# Make a dataframe out of it and add the original index to recover it later\n",
    "ref_rp = ref_rp.to_frame('geometry')\n",
    "ref_rp['orig_index'] = df_ref.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adapted-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read region file\n",
    "reg_f = gpd.read_file(reg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dense-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the overlay with the RGI region of interest -> get the rep. points which are located inside the region boundaries\n",
    "ref_intersect = gpd.overlay(ref_rp, reg_f.loc[reg_f.RGI_CODE == f'{reg:02d}'], how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "covered-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now select the entries which intersect from the original shape file (-> extract the polygons) \n",
    "ref_odf = df_ref.loc[ref_intersect['orig_index'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-marketplace",
   "metadata": {},
   "source": [
    "## Compare new RGI-file and reference data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-papua",
   "metadata": {},
   "source": [
    "### Number of elements (differences do not necessarily depict major problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "increased-preserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of glaciers in new RGI subset: 37426\n",
      "Number of glaciers in reference data: 37566\n",
      "Difference: -140\n"
     ]
    }
   ],
   "source": [
    "print('Number of glaciers in new RGI subset:', len(RGI_ss))\n",
    "print('Number of glaciers in reference data:', len(ref_odf))\n",
    "print('Difference:', len(RGI_ss)-len(ref_odf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-fellow",
   "metadata": {},
   "source": [
    "### Total area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "based-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an area field to the selected GAMDAM table\n",
    "ref_odf['area'] = ref_odf.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dietary-productivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area RGI [km²]: 33075.25200985853\n",
      "Area Ref [km²]: 33075.25028047181\n",
      "Area difference [km²]: 0.0017293867203989066\n"
     ]
    }
   ],
   "source": [
    "# print and compare area values\n",
    "Area_RGI = RGI_ss['area'].sum() * 1e-6\n",
    "print('Area RGI [km²]:', Area_RGI)\n",
    "Area_ref = ref_odf['area'].sum() * 1e-6\n",
    "print('Area Ref [km²]:', Area_ref)\n",
    "d = (Area_RGI - Area_ref)\n",
    "print('Area difference [km²]:',d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-enforcement",
   "metadata": {},
   "source": [
    "**We believe that remaining errors are of the same type as Region 01: multipolygons that weren't properly ingested in GLIMS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-wagner",
   "metadata": {},
   "source": [
    "### Comparison with RGI6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "centered-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to know the name of the file to open from zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile(rgi6_reg_file, \"r\") as z:\n",
    "    for f in z.filelist:\n",
    "        if '.shp' in f.filename:\n",
    "            fname = f.filename\n",
    "\n",
    "# load reference data\n",
    "rgi6_odf = gpd.read_file('zip://' + rgi6_reg_file + '/' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "organized-reflection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of glaciers in new RGI subset: 37426\n",
      "Number of glaciers in RGI6 data: 27988\n",
      "Difference: 9438\n"
     ]
    }
   ],
   "source": [
    "print('Number of glaciers in new RGI subset:', len(RGI_ss))\n",
    "print('Number of glaciers in RGI6 data:', len(rgi6_odf))\n",
    "print('Difference:', len(RGI_ss)-len(rgi6_odf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nervous-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi6_odf['area'] = rgi6_odf.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "convertible-liberty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area RGI7 [km²]: 33075.25200985853\n",
      "Area RGI6 [km²]: 33568.187227219205\n",
      "Area difference [km²]: -492.93521736067487\n"
     ]
    }
   ],
   "source": [
    "# print and compare area values\n",
    "Area_RGI = RGI_ss['area'].sum() * 1e-6\n",
    "print('Area RGI7 [km²]:', Area_RGI)\n",
    "Area_ref = rgi6_odf['area'].sum() * 1e-6\n",
    "print('Area RGI6 [km²]:', Area_ref)\n",
    "d = (Area_RGI - Area_ref)\n",
    "print('Area difference [km²]:',d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-punishment",
   "metadata": {},
   "source": [
    "# End of revised notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-planner",
   "metadata": {},
   "source": [
    "## Optional: identify Identify potentially problematic cases and write them to a shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "built-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay RGI file with reference data set to evaluate differences (some computational effort)\n",
    "delta_shape = gpd.overlay(RGI_ss, ref_odf , how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "final-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with the geometry area\n",
    "delta_shape['area'] = delta_shape.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "frank-republican",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract all geometries larger than a threshold \n",
    "#10000 m² = 0,01 km² which is the common threshold for glaciers to be included in inventories\n",
    "thr = 3000 \n",
    "df_d = delta_shape.loc[delta_shape['area'] > thr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "powerful-impact",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a file which contains the spatial features which were defined as problematic as above\n",
    "prob_IDs = RGI_ss.loc[df_d.glac_id.isin(RGI_ss.glac_id).index]\n",
    "\n",
    "# and write it to shapefile\n",
    "td = f'{testout}/RGI_R{reg:02d}probs.shp'\n",
    "prob_IDs.to_file(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-footage",
   "metadata": {},
   "source": [
    "### Do the same for the reference data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "spare-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay the representative Points of refernce data and and the above geometries to identify the same glaciers\n",
    "df_d_ref_p = gpd.overlay(ref_rp, prob_IDs, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "obvious-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Now select the entries which intersect from the original shape file (-> extract the polygons) \n",
    "df_d_ref = df_ref.loc[df_d_ref_p['orig_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "innocent-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with the shape area\n",
    "df_d_ref['area'] = df_d_ref.to_crs({'proj':'cea'}).area\n",
    "\n",
    "# and write it to shapefile\n",
    "td = f'{testout}/R{reg:02d}refprobs.shp'\n",
    "df_d_ref.to_file(td)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
