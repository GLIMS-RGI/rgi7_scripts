{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vocal-wrist",
   "metadata": {},
   "source": [
    "# RGI-07: Region 17 (Southern Andes)\n",
    "##### F. Roura November 2021\n",
    "\n",
    "Goal: compare L2 GLIMS files to original inventory to check possible errors in GLIMS ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "from utils import mkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-antique",
   "metadata": {},
   "source": [
    "## Files and storage paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of interest\n",
    "reg = 17\n",
    "\n",
    "# go down from rgi7_scripts/workflow\n",
    "data_dir = '../../rgi7_data/'\n",
    "\n",
    "# Level 2 GLIMS files\n",
    "l2_dir = os.path.join(data_dir, 'l2_sel_reg_tars')\n",
    "\n",
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_rgi7a'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_rgi7a_tar'))\n",
    "\n",
    "# Original inventory for GLIMS check \n",
    "ref_reg_file = os.path.join(data_dir, 'l0_support_data', 'Shape_Inventario_de_Glaciares.zip') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-gathering",
   "metadata": {},
   "source": [
    "### Load the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read L2 files from GLIMS\n",
    "shp = gpd.read_file('tar://' + l2_dir + f'/RGI{reg:02d}.tar.gz/RGI{reg:02d}/RGI{reg:02d}.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd82380-d34d-495e-96a7-df87bdfedf83",
   "metadata": {},
   "source": [
    "## List of submissions in GLIMS L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e086acc-4f4e-4e15-ba52-77f381850d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "toprint = []\n",
    "for subid in shp.subm_id.unique():\n",
    "    s_loc = shp.loc[shp.subm_id == subid]\n",
    "    s = ''\n",
    "    for c in ['subm_id', 'analysts', 'src_date']:\n",
    "        toprint = s_loc[c].unique()\n",
    "        if c != 'src_date':\n",
    "            s += ' ' + (str(toprint[0]))\n",
    "        else:\n",
    "            for d in toprint:\n",
    "                s += ' ' + d[:4]\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-industry",
   "metadata": {},
   "source": [
    "## Apply selection criteria to compare Glims data set to the original one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-cabin",
   "metadata": {},
   "source": [
    "### Step 1: extract ingested inventory from GLIMS data and do a check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...extract l2 from GLIMS based on 'sumb_id'\n",
    "RGI_ss = shp.loc[shp['subm_id'] == 730].copy() #barcaza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-wallace",
   "metadata": {},
   "source": [
    "#### load reference data (here original inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to know the name of the file to open from zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile(ref_reg_file, \"r\") as z:\n",
    "    for f in z.filelist:\n",
    "        if 'Inventario_de_Glaciares.shp' in f.filename:\n",
    "            if '.shp.xml' in f.filename:\n",
    "                break\n",
    "            else:\n",
    "                fname = f.filename\n",
    "\n",
    "# load reference data\n",
    "ref_odf = gpd.read_file('zip://' + ref_reg_file + '/' + fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-college",
   "metadata": {},
   "source": [
    "#### Number of elements (differences do not necessarily depict major problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of glaciers in new RGI subset:', len(RGI_ss))\n",
    "print('Number of glaciers in reference data:', len(ref_odf))\n",
    "print('Difference:', len(RGI_ss)-len(ref_odf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-configuration",
   "metadata": {},
   "source": [
    "#### check for dublicate glacier IDs: many glaciers have shared id. Let's see how many of them are actually different glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015f847-1c73-4cb7-afdf-19932110c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ref_odf['OBJECTID'].unique())-len(ref_odf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfb845-17ff-416a-b160-e1064301deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ref_odf['OBJECTID'].unique()))\n",
    "print(len(ref_odf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74768d-d188-4994-8d9d-88763e56e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset ref_odf to work with the subset that has not unique IDs\n",
    "rep_id = gpd.geodataframe.GeoDataFrame()\n",
    "for idi in ref_odf['OBJECTID'].unique():\n",
    "    if len(ref_odf.loc[ref_odf['OBJECTID']==idi]) > 1:\n",
    "        rep_id = pd.concat([rep_id, ref_odf.loc[ref_odf['OBJECTID']==idi]])\n",
    "        print(len(ref_odf.loc[ref_odf['OBJECTID']==idi]), idi)\n",
    "rep_id['OBJECTID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94ef74-14f6-4584-a7bc-8b99aa6d3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Repeated Ids:\n",
    "tmp_ids = rep_id['OBJECTID'].unique()\n",
    "\n",
    "## find if the glaciers with same are actually the same glacier or not:\n",
    "for tmp in tmp_ids:\n",
    "    tmp_set = rep_id.loc[rep_id['OBJECTID'] == tmp]\n",
    "## number of total glaciers with reperated IDs but different other attributes:\n",
    "    print( 'Repeated Id: ', tmp, '; glaciers with this id based on \"geometry\": ', len(tmp_set['geometry'].unique()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172343b-7c72-4344-846a-c0c1dc0f380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_id.loc[rep_id[\"OBJECTID\"]==4201].plot() # --> repeated ID not repeated geometry. (different geometries with same ID)\n",
    "rep_id.loc[rep_id[\"OBJECTID\"]==4721].plot() # --> repeated ID not repeated geometry. (different geometries with same ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e1e9b-647f-4b4e-8f4b-f68041c165ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_id.loc[rep_id[\"OBJECTID\"]==330].plot() # --> repeated ID and geometry. (glacier with ID=330 is twice in the dataset)\n",
    "rep_id.loc[rep_id[\"OBJECTID\"]==1364].plot() #--> repeated ID and geometry. (glacier with ID=1364 is twice in the dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bddeb0-6b9c-4234-b4d5-2aac766780cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_id.loc[rep_id[\"OBJECTID\"]==1996].plot() # --> repeated ID not repeated geometry. (different geometries with same ID)\n",
    "rep_id.loc[rep_id[\"OBJECTID\"]==6559].plot() # --> repeated ID not repeated geometry. (different geometries with same ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2ffad-fbc4-4b6b-a7e3-1421986cdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(rep_id.iloc[])==np.array(rep_id.iloc[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06bd6a-5f93-4b86-915b-e15da27d2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare all the elements inside the repeated id == 0\n",
    "## many loops but it's how i managed to do it...\n",
    "rep_id0 = rep_id.loc[rep_id[\"OBJECTID\"] == 0]\n",
    "for id0 in range(0,len(rep_id0)): ## loop all entries\n",
    "    tmp = list(range(0,id0)) + list(range(id0+1,len(rep_id0))) ## all entries minus the current one\n",
    "    for item in tmp: ## loop all entries except the current one\n",
    "        alltrue = sum(np.array(rep_id.iloc[item]) == np.array(rep_id.iloc[id0]))\n",
    "        if alltrue == 67:\n",
    "            print('current equal glaciers in ids ', id0, ' and ', item)\n",
    "\n",
    "## we don'tget any message, so there are not 2 identical entries in the id=0 subset\n",
    "## --> number of glaciers is the length of the subset:\n",
    "len(rep_id0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f9fb9-5fa7-4ae7-a99c-6757bdd1a1ce",
   "metadata": {},
   "source": [
    "## we have 432 glaciers with repeated id=0 (+432), 2 glaciers repeated (identical entries) (-2), 4 repeated ids that represent different polygons (2+1+1+1 = +5) --> total glaciers are \"non repeated\" + 432+2+5=439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5a878-024f-442b-84b4-1d475d8d02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rep_id.iloc[id0-1][2]==np.none)\n",
    "#== rep_id.iloc[id0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de0be1-7743-4b48-8ea1-188661f2c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rep_id.loc[rep_id[id0][rep_id.iloc[id0]!=rep_id.iloc[id0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9490f05-d084-43ad-9d40-63c85f6c2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rep_id0.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fd190-6c11-4bf4-b082-0e60f6bbb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = list(range(0,5)) + list(range(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e7156-119a-4ca4-9850-c651c90b53df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rep_id0.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5fac9-00fd-44fa-a7a0-c74b29fe3c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7196aa8-2362-45fd-90da-0d32b321f623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400cbef-48fa-4a44-88a6-3d26418a7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_id.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8744ca6-1eb7-4a3a-afe7-c180287a1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(rep_id[0:5], \"test_file.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addea4b-4f9a-4089-8964-14ae727517d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_id[0:1]['COD_GLA']==rep_id[0:1]['COD_GLA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52c584-11c4-4831-8dd0-dbcd0a14850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_id.iloc[0]['COD_GLA']==rep_id.iloc[0]['COD_GLA']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dublicate IDs in original:', len(ref_odf)-len(ref_odf['OBJECTID'].unique()))\n",
    "print('Dublicate IDs in GLIMS:', len(RGI_ss)-len(RGI_ss['glac_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-worker",
   "metadata": {},
   "source": [
    "#### Total area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an area field to RGI_ss and reference data\n",
    "RGI_ss['area'] = RGI_ss.to_crs({'proj':'cea'}).area\n",
    "ref_odf['area'] = ref_odf.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and compare area values\n",
    "Area_Rep = RGI_ss['area'].sum()/1000000\n",
    "print('Area Rep [km²]:', Area_Rep)\n",
    "Area_RGI6 = ref_odf['area'].sum()/1000000\n",
    "print('Area RGI6 [km²]:', Area_RGI6)\n",
    "d = (Area_Rep - Area_RGI6)\n",
    "d_perc = (d/Area_Rep*100)\n",
    "print('Area difference [km²]:',d,'/','percentage:', d_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-needle",
   "metadata": {},
   "source": [
    "### result of check (RGI from GLIMS L2 and original inventory):\n",
    "#### difference in number of glaciers: 438\n",
    "#### duplicate IDs: 0 in RGI, 438\n",
    "#### nominal glaciers: 0\n",
    "#### area difference: 2.9 km² / 0.13 % (related to edited outlines at a volcano in Ecuador (G281556E00697S, G281572E00688S, G281559E00671S, G281551E00681S))\n",
    "#### general comment: in general reproduction works...differences need more detailed check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-camcorder",
   "metadata": {},
   "source": [
    "## Write out and tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "RGI_ss.to_file(dd + f'RGI{reg:02d}.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))## Write out and tar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-fishing",
   "metadata": {},
   "source": [
    "## Find missing glaciers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import haversine\n",
    "import numpy as np\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_coord(geom):\n",
    "    \"\"\"To compute CenLon CenLat ourselves\"\"\"\n",
    "    x, y = geom.xy\n",
    "    return x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = ref_odf.copy()\n",
    "rgi7 = RGI_ss.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nominal\n",
    "df_ref = df_ref.loc[df_ref.Status != 2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CenLon CenLat ourselves\n",
    "rp = df_ref.representative_point()\n",
    "\n",
    "coordinates = np.array(list(rp.apply(xy_coord)))\n",
    "df_ref['CenLon'] = coordinates[:, 0]\n",
    "df_ref['CenLat'] = coordinates[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_orig = df_ref.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all RGI7 glaciers and find their equivalent in ref\n",
    "df_ref = df_ref_orig.copy()\n",
    "not_found = {}\n",
    "to_drop = []\n",
    "for i, (ref_area, lon, lat) in progressbar.progressbar(enumerate(zip(rgi7['area'].values, rgi7.CenLon.values, rgi7.CenLat.values)), max_value=len(rgi7)):\n",
    "#     dist = haversine(lon, lat, df_ref.CenLon.values, df_ref.CenLat.values)\n",
    "    dist = (lon - df_ref.CenLon.values)**2 + (lat - df_ref.CenLat.values)**2 \n",
    "    found = False\n",
    "    for j in np.argsort(dist)[:10]:\n",
    "        s6 = df_ref.iloc[j]\n",
    "        if np.allclose(s6['area'], ref_area, rtol=0.001):\n",
    "            found = True\n",
    "            to_drop.append(s6.name)\n",
    "            break\n",
    "    if not found:\n",
    "        not_found[i] = df_ref.iloc[np.argsort(dist)[:10]]\n",
    "    if len(to_drop) > 1000:\n",
    "        df_ref.drop(labels=to_drop, inplace=True)\n",
    "        to_drop = []\n",
    "df_ref.drop(labels=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(not_found), len(df_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_rgi7 = rgi7.iloc[list(not_found.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_rgi7.plot(edgecolor='k');\n",
    "plt.title('GLIMS');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.plot(edgecolor='k');\n",
    "plt.title('RGI6');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_problem_glaciers'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_problem_glaciers_tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "pb_rgi7.to_file(dd + f'RGI{reg:02d}_glims.shp')\n",
    "df_ref.to_file(dd + f'RGI{reg:02d}_ref.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-ensemble",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
