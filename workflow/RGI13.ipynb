{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "collected-future",
   "metadata": {},
   "source": [
    "# RGI-07: Region 13\n",
    "\n",
    "F. Maussion & S. Galos, June 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from utils import mkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-friendship",
   "metadata": {},
   "source": [
    "### specify RGI-region and storage paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of interest\n",
    "reg = 13\n",
    "\n",
    "# go down from rgi7_scripts/workflow\n",
    "data_dir = '../../rgi7_data/'\n",
    "\n",
    "# Level 2 GLIMS files\n",
    "l2_dir = os.path.join(data_dir, 'l2_sel_reg_tars')\n",
    "\n",
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_rgi7a'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_rgi7a_tar'))\n",
    "\n",
    "# RGI v6 file for comparison later \n",
    "rgi6_reg_file = os.path.join(data_dir, 'l0_RGIv6', '13_rgi60_CentralAsia.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region is based on GAMDAM, use for comparison\n",
    "support_dir = os.path.join(data_dir, 'l0_support_data')\n",
    "gamdam_dir = os.path.join(support_dir, 'gamdam')\n",
    "\n",
    "# Region file to select from gamdam\n",
    "reg_file = os.path.join(data_dir, 'l0_regions', '00_rgi70_regions', '00_rgi70_O1Regions.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-maldives",
   "metadata": {},
   "source": [
    "### Load the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read L2 files\n",
    "shp = gpd.read_file('tar://' + l2_dir + f'/RGI{reg:02d}.tar.gz/RGI{reg:02d}/RGI{reg:02d}.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-trout",
   "metadata": {},
   "source": [
    "### Apply selection criteria to create the RGI-07 data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to get the data relevant for RGI07 and select by attributes\n",
    "rgi7 = shp.loc[shp['analysts'] == 'Sakai, Akiko']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-preference",
   "metadata": {},
   "source": [
    "## Write out and tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "rgi7.to_file(dd + f'RGI{reg:02d}.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-russia",
   "metadata": {},
   "source": [
    "## New RGI-file created - Check result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-teach",
   "metadata": {},
   "source": [
    "### load reference data (here GAMDAM original) to enable comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify path to reference data set\n",
    "import zipfile\n",
    "import glob\n",
    "gam_files = glob.glob(gamdam_dir + '/*.zip')\n",
    "df_ref = []\n",
    "for gf in gam_files:\n",
    "    # Just to know the name of the file to open from zip\n",
    "    with zipfile.ZipFile(gf, \"r\") as z:\n",
    "        for f in z.filelist:\n",
    "            if '.shp' in f.filename:\n",
    "                fname = f.filename\n",
    "    df_ref.append(gpd.read_file('zip://' + gf + '/' + fname))\n",
    "\n",
    "df_ref = pd.concat(df_ref).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate representative points for reference data\n",
    "ref_rp = df_ref.representative_point()\n",
    "\n",
    "# Make a dataframe out of it and add the original index to recover it later\n",
    "ref_rp = ref_rp.to_frame('geometry')\n",
    "ref_rp['orig_index'] = df_ref.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read region file\n",
    "reg_f = gpd.read_file(reg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the overlay with the RGI region of interest -> get the rep. points which are located inside the region boundaries\n",
    "ref_intersect = gpd.overlay(ref_rp, reg_f.loc[reg_f.RGI_CODE == f'{reg:02d}'], how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now select the entries which intersect from the original shape file (-> extract the polygons) \n",
    "df_ref = df_ref.loc[ref_intersect['orig_index'].values].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-karaoke",
   "metadata": {},
   "source": [
    "## Compare new RGI-file and reference data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-packet",
   "metadata": {},
   "source": [
    "### Number of elements (differences do not necessarily depict major problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of glaciers in new RGI subset:', len(rgi7))\n",
    "print('Number of glaciers in reference data:', len(df_ref))\n",
    "print('Difference:', len(rgi7)-len(df_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-block",
   "metadata": {},
   "source": [
    "### Total area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an area field to the selected GAMDAM table\n",
    "df_ref['area'] = df_ref.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and compare area values\n",
    "Area_RGI = rgi7['area'].sum() * 1e-6\n",
    "print('Area RGI [km²]:', Area_RGI)\n",
    "Area_ref = df_ref['area'].sum() * 1e-6\n",
    "print('Area Ref [km²]:', Area_ref)\n",
    "d = (Area_RGI - Area_ref)\n",
    "print('Area difference [km²]:',d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-projection",
   "metadata": {},
   "source": [
    "**We believe that remaining errors are of the same type as Region 01: multipolygons that weren't properly ingested in GLIMS.** We will check this below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-renewal",
   "metadata": {},
   "source": [
    "### Comparison with RGI6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to know the name of the file to open from zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile(rgi6_reg_file, \"r\") as z:\n",
    "    for f in z.filelist:\n",
    "        if '.shp' in f.filename:\n",
    "            fname = f.filename\n",
    "\n",
    "# load reference data\n",
    "rgi6 = gpd.read_file('zip://' + rgi6_reg_file + '/' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of glaciers in new RGI subset:', len(rgi7))\n",
    "print('Number of glaciers in RGI6 data:', len(rgi6))\n",
    "print('Difference:', len(rgi7)-len(rgi6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi6['area'] = rgi6.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and compare area values\n",
    "Area_RGI = rgi7['area'].sum() * 1e-6\n",
    "print('Area RGI7 [km²]:', Area_RGI)\n",
    "Area_ref = rgi6['area'].sum() * 1e-6\n",
    "print('Area RGI6 [km²]:', Area_ref)\n",
    "d = (Area_RGI - Area_ref)\n",
    "print('Area difference [km²]:',d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-service",
   "metadata": {},
   "source": [
    "# End of revised notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-starter",
   "metadata": {},
   "source": [
    "## Find missing glaciers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import haversine\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_coord(geom):\n",
    "    \"\"\"To compute CenLon CenLat ourselves\"\"\"\n",
    "    x, y = geom.xy\n",
    "    return x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CenLon CenLat ourselves\n",
    "rp = df_ref.representative_point()\n",
    "\n",
    "coordinates = np.array(list(rp.apply(xy_coord)))\n",
    "df_ref['CenLon'] = coordinates[:, 0]\n",
    "df_ref['CenLat'] = coordinates[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_orig = df_ref.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all RGI7 glaciers and find their equivalent in ref\n",
    "df_ref = df_ref_orig.copy()\n",
    "not_found = {}\n",
    "to_drop = []\n",
    "for i, (ref_area, lon, lat) in progressbar.progressbar(enumerate(zip(rgi7['area'].values, rgi7.CenLon.values, rgi7.CenLat.values)), max_value=len(rgi7)):\n",
    "#     dist = haversine(lon, lat, df_ref.CenLon.values, df_ref.CenLat.values)\n",
    "    dist = (lon - df_ref.CenLon.values)**2 + (lat - df_ref.CenLat.values)**2 \n",
    "    found = False\n",
    "    for j in np.argsort(dist)[:10]:\n",
    "        s6 = df_ref.iloc[j]\n",
    "        if np.allclose(s6['area'], ref_area, rtol=0.001):\n",
    "            found = True\n",
    "            to_drop.append(s6.name)\n",
    "            break\n",
    "    if not found:\n",
    "        not_found[i] = df_ref.iloc[np.argsort(dist)[:10]]\n",
    "    if len(to_drop) > 1000:\n",
    "        df_ref.drop(labels=to_drop, inplace=True)\n",
    "        to_drop = []\n",
    "df_ref.drop(labels=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(not_found), len(df_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_rgi7 = rgi7.iloc[list(not_found.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(not_found.keys()):\n",
    "    ax = rgi7.iloc[[k]].plot(edgecolor='k');\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_problem_glaciers'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_problem_glaciers_tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "pb_rgi7.to_file(dd + f'RGI{reg:02d}_glims.shp')\n",
    "df_ref.to_file(dd + f'RGI{reg:02d}_ref.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
