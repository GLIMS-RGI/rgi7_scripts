{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-timer",
   "metadata": {},
   "source": [
    "# RGI06 (Iceland)\n",
    "\n",
    "F. Maussion & S. Galos\n",
    "\n",
    "Strictly equivalent to RGI6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from utils import mkdir, submission_summary, needs_size_filter, size_filter, plot_map, plot_date_hist\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-counter",
   "metadata": {},
   "source": [
    "## Files and storage paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of interest\n",
    "reg = 6\n",
    "\n",
    "# go down from rgi7_scripts/workflow\n",
    "data_dir = '../../rgi7_data/'\n",
    "\n",
    "# Level 2 GLIMS files\n",
    "l2_dir = os.path.join(data_dir, 'l2_sel_reg_tars')\n",
    "\n",
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_rgi7a'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_rgi7a_tar'))\n",
    "\n",
    "# RGI v6 file for comparison later \n",
    "rgi6_reg_file = os.path.join(data_dir, 'l0_RGIv6', '06_rgi60_Iceland.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific to this region: RGI is made up by a series of spatially overlapping datasets\n",
    "# selection of subsets is based on boxes which define areas for respective subset selection\n",
    "\n",
    "support_dir = os.path.join(data_dir, 'l0_support_data')\n",
    "box_file = os.path.join(support_dir, 'Iceland.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-sense",
   "metadata": {},
   "source": [
    "### Load the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read L2 files\n",
    "shp = gpd.read_file('tar://' + l2_dir + f'/RGI{reg:02d}.tar.gz/RGI{reg:02d}/RGI{reg:02d}.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4adc027-324e-4b43-9ae7-a0a4c6545bb7",
   "metadata": {},
   "source": [
    "### List of submissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6c455-161a-45bd-9ab9-39d52e668012",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf, _ = submission_summary(shp)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36ca4b-dff9-488d-8bcc-5f1c38d384f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write out selection in intermediate shape files for manual GIS review\n",
    "# tmp_output_dir = mkdir(os.path.join(data_dir, 'l0_tmp_data', f'rgi{reg:02d}_inventories'))\n",
    "# tmp_output_dir_tar = mkdir(os.path.join(data_dir, 'l0_tmp_data'))\n",
    "# for subid in shp.subm_id.unique():\n",
    "#     s_loc = shp.loc[shp.subm_id == subid]\n",
    "#     s_loc.to_file(tmp_output_dir + f'/subm_{int(subid):03d}.shp')\n",
    "# print('Taring...')\n",
    "# print(subprocess.run(['tar', '-zcvf', f'{tmp_output_dir_tar}/rgi{reg:02d}_inventories.tar.gz', '-C', \n",
    "#                       os.path.join(data_dir, 'l0_tmp_data'), f'rgi{reg:02d}_inventories']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-comment",
   "metadata": {},
   "source": [
    "## Apply selection criteria to create the RGI7 data subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-criterion",
   "metadata": {},
   "source": [
    "### Extract RGI6 from GLIMS data and do a check\n",
    "\n",
    "In this special case RGI06 was made up from several files. Submission id 719 was added to GLIMS to document applied changes in glacier devides for RGI6 so data set serves as the baseline, we then add those parts of other submissions which are not covered by subm_id 719. To extract those we apply an overlay of representative points of each file and the polygons of subm_id 719.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define subsets according to submission id\n",
    "sub_719 = shp.loc[shp['subm_id']==719]\n",
    "sub_437 = shp.loc[shp['subm_id']==437]\n",
    "sub_438 = shp.loc[shp['subm_id']==438]\n",
    "sub_439 = shp.loc[shp['subm_id']==439]\n",
    "sub_452 = shp.loc[shp['subm_id']==452]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-greenhouse",
   "metadata": {},
   "source": [
    "### Extract relevant subset of each submission based on overlay with manually defined boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shapes\n",
    "AOI_437 = gpd.read_file('tar://' + box_file + '/Iceland/AOI_437.shp')\n",
    "AOI_438 = gpd.read_file('tar://' + box_file + '/Iceland/AOI_438.shp')\n",
    "AOI_439 = gpd.read_file('tar://' + box_file + '/Iceland/AOI_439.shp')\n",
    "AOI_452 = gpd.read_file('tar://' + box_file + '/Iceland/AOI_452.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract relevant subsets by overlay\n",
    "\n",
    "# 437\n",
    "sub437_ss = gpd.overlay(sub_437, AOI_437, how='intersection')\n",
    "\n",
    "# 438\n",
    "sub438_ss = gpd.overlay(sub_438, AOI_438, how='intersection')\n",
    "\n",
    "# 439\n",
    "sub439_ss = gpd.overlay(sub_439, AOI_439, how='intersection')\n",
    "\n",
    "# 452\n",
    "sub452_ss = gpd.overlay(sub_452, AOI_452, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to subm 719 in order to create RGI regional subset\n",
    "rgi7 = sub_719.append([sub437_ss, sub438_ss, sub439_ss, sub452_ss], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79435ad7-e3b5-4d6f-93fe-e871bc6ff75a",
   "metadata": {},
   "source": [
    "### Some sanity checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7567693-4a21-4956-b814-18380675e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf, df_class = submission_summary(rgi7)\n",
    "df_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d977d7-9498-4d00-b7b5-582630cb89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing should change here\n",
    "rgi7['is_rgi6'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee41170-a3e1-4719-8b6d-c422d3792426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the orphaned rock outcrops\n",
    "orphan_f = os.path.join(data_dir, 'l1_orphan_interiors', f'RGI{reg:02d}', f'RGI{reg:02d}.shp')\n",
    "if os.path.exists(orphan_f):\n",
    "    orphan_f = gpd.read_file(orphan_f)\n",
    "    if np.any(np.isin(rgi7.subm_id.unique(), orphan_f.subm_id.unique())):\n",
    "        print('Orphan rock outcrops detected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d21ec-6ad5-483c-8981-a4b6509bada2",
   "metadata": {},
   "source": [
    "### Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f10c4-edb3-4099-b0ab-c87ab3fddbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(rgi7, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca975d5c-9c52-4815-905f-2adf891c92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(rgi7, reg, is_rgi6=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96596a7c-1008-4e81-979b-65a31c4abe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_date_hist(rgi7, reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d93507-100b-426c-beea-b5e73d38976e",
   "metadata": {},
   "source": [
    "### Text for github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c1234-4c88-49eb-b436-de3b6b8a85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgh = sdf.T\n",
    "fgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de91c9-22a2-4a63-81af-20134b9cec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fgh.to_markdown(headers=np.append(['subm_id'], fgh.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f74d2-6186-4e56-af6f-6829305635a6",
   "metadata": {},
   "source": [
    "## Write out and tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf1859-5ff7-4c60-b8dc-4d44029394ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "rgi7.to_file(dd + f'RGI{reg:02d}.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-haiti",
   "metadata": {},
   "source": [
    "### load reference data (here RGI6) to enable comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reference data\n",
    "from utils import open_zip_shapefile\n",
    "ref_odf = open_zip_shapefile(rgi6_reg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-matter",
   "metadata": {},
   "source": [
    "#### Number of elements (differences depict problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of glaciers in new RGI subset:', len(rgi7))\n",
    "print('Number of glaciers in reference data:', len(ref_odf))\n",
    "print('Difference:', len(rgi7)-len(ref_odf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many nominals in RGI06 (identifiable via 'Status' attribute in RGI 06)\n",
    "nom = ref_odf.loc[ref_odf.Status == 2]\n",
    "len(nom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-thirty",
   "metadata": {},
   "source": [
    "#### Total area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an area field to RGI_ss and reference data\n",
    "ref_odf['area'] = ref_odf.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and compare area values\n",
    "Area_RGI = rgi7['area'].sum()/1000000\n",
    "print('Area RGI [km²]:', Area_RGI)\n",
    "Area_ref = ref_odf['area'].sum()/1000000\n",
    "print('Area Ref [km²]:', Area_ref)\n",
    "d = (Area_RGI - Area_ref)\n",
    "print('Area difference:',d, 'km²')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-representation",
   "metadata": {},
   "source": [
    "### Find the missing glacier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename things\n",
    "df_ref = ref_odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import haversine\n",
    "import progressbar\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_coord(geom):\n",
    "    \"\"\"To compute CenLon CenLat ourselves\"\"\"\n",
    "    x, y = geom.xy\n",
    "    return x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CenLon CenLat ourselves\n",
    "rp = df_ref.representative_point()\n",
    "\n",
    "coordinates = np.array(list(rp.apply(xy_coord)))\n",
    "df_ref['CenLon'] = coordinates[:, 0]\n",
    "df_ref['CenLat'] = coordinates[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_orig = df_ref.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all RGI7 glaciers and find their equivalent in ref\n",
    "df_ref = df_ref_orig.copy()\n",
    "not_found = {}\n",
    "to_drop = []\n",
    "for i, (ref_area, lon, lat) in progressbar.progressbar(enumerate(zip(rgi7['area'].values, rgi7.CenLon.values, rgi7.CenLat.values)), max_value=len(rgi7)):\n",
    "#     dist = haversine(lon, lat, df_ref.CenLon.values, df_ref.CenLat.values)\n",
    "    dist = (lon - df_ref.CenLon.values)**2 + (lat - df_ref.CenLat.values)**2 \n",
    "    found = False\n",
    "    for j in np.argsort(dist)[:10]:\n",
    "        s6 = df_ref.iloc[j]\n",
    "        if np.allclose(s6['area'], ref_area, rtol=0.01):\n",
    "            found = True\n",
    "            to_drop.append(s6.name)\n",
    "            break\n",
    "    if not found:\n",
    "        not_found[i] = df_ref.iloc[np.argsort(dist)[:10]]\n",
    "    if len(to_drop) > 1000:\n",
    "        df_ref.drop(labels=to_drop, inplace=True)\n",
    "        to_drop = []\n",
    "df_ref.drop(labels=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(not_found), len(df_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_rgi7 = rgi7.iloc[list(not_found.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi7.iloc[list(not_found.keys())].plot(edgecolor='k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.plot(edgecolor='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-substitute",
   "metadata": {},
   "source": [
    "We have found the problem! Reported here: https://trello.com/c/Q7QOMnkA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_problem_glaciers'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_problem_glaciers_tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "pb_rgi7.to_file(dd + f'RGI{reg:02d}_glims.shp')\n",
    "df_ref.to_file(dd + f'RGI{reg:02d}_ref.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-attendance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
