{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "executed-gamma",
   "metadata": {},
   "source": [
    "# RGI-07: Region 03 (Arctic Canada North)\n",
    "\n",
    "##### F. Maussion & S. Galos, August 2021\n",
    "\n",
    "Goal: RGI6 everywhere, except elsemere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moderate-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os\n",
    "from utils import mkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-oxygen",
   "metadata": {},
   "source": [
    "## Files and storage paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "painful-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of interest\n",
    "reg = 3\n",
    "\n",
    "# go down from rgi7_scripts/workflow\n",
    "data_dir = '../../rgi7_data/'\n",
    "\n",
    "# Level 2 GLIMS files\n",
    "l2_dir = os.path.join(data_dir, 'l2_sel_reg_tars')\n",
    "\n",
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_rgi7a'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_rgi7a_tar'))\n",
    "\n",
    "# RGI v6 file for comparison later \n",
    "rgi6_reg_file = os.path.join(data_dir, 'l0_RGIv6', '03_rgi60_ArcticCanadaNorth.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-paraguay",
   "metadata": {},
   "source": [
    "### Load the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surgical-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read L2 files\n",
    "shp = gpd.read_file('tar://' + l2_dir + f'/RGI{reg:02d}.tar.gz/RGI{reg:02d}/RGI{reg:02d}.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b15b1a-32d4-44be-8611-a61c61271243",
   "metadata": {},
   "source": [
    "### List of submissions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218ab3f5-934b-4ed7-bbce-a034cf87bdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subm ID: 255. N=626. Hartman, Gregory 1999\n",
      "Subm ID: 356. N=200. Hartman, Gregory 1997\n",
      "Subm ID: 358. N=178. Hartman, Gregory 1999\n",
      "Subm ID: 359. N=183. Cawkwell, Fiona 2002\n",
      "Subm ID: 590. N=4541. Barrand, Nick; Burgess, Dave; Cawkwell, Fiona; Copland, Luke; Filbert, Katie; Gardner, Alex; Hartmann, G; OCallaghan, P; Paul, Frank; Sharp, Martin; Wolken, G.; Wyatt, F. 1999 1999\n",
      "Subm ID: 625. N=4. Braun, Carsten; Raup, Bruce H. 1959\n",
      "Subm ID: 626. N=4. Bradley, Raymond; Braun, Carsten; Hardy, Douglas 2001\n",
      "Subm ID: 627. N=2. Raup, Bruce H. 2001\n",
      "Subm ID: 628. N=2. Raup, Bruce H. 2005\n",
      "Subm ID: 629. N=2. Raup, Bruce H. 2007\n",
      "Subm ID: 630. N=2. Raup, Bruce H. 2009\n",
      "Subm ID: 631. N=2. Raup, Bruce H. 2014\n",
      "Subm ID: 632. N=3. Raup, Bruce H. 2015\n",
      "Subm ID: 633. N=2. Raup, Bruce H. 2016\n",
      "Subm ID: 634. N=2. Raup, Bruce H. 2016\n",
      "Subm ID: 635. N=7. Berthier, Etienne; Bolch, Tobias; Cogley, Graham; Kienholz, Christian 1988\n",
      "Subm ID: 645. N=2. Raup, Bruce H. 2017\n",
      "Subm ID: 660. N=10. Maydhisudhiwongs, Pim; Raup, Bruce H. 2017\n",
      "Subm ID: 661. N=12. Maydhisudhiwongs, Pim; Raup, Bruce H. 2016\n",
      "Subm ID: 711. N=1569. Copland, Luke; White, Adrienne 1999 1999 1999 1999\n",
      "Subm ID: 712. N=442. Copland, Luke; White, Adrienne 2002 2003 2009 2008 2002 2009\n",
      "Subm ID: 713. N=2154. Copland, Luke; White, Adrienne 2015 2015 2015 2015 2015 2015 2015 2015 2015 2016 2015\n",
      "Subm ID: 723. N=2583. Paul, Frank; Rastner, Philipp; White, Adrienne 1999 1999 2010 2019 1999\n",
      "Subm ID: 728. N=1968. Copland, Luke; Kochtitzky, William; Thomson, Laura; Zajaczkiwsky, Sophie 1999 2000 1999 1999 2000 2000 1999 1999 2002 1999 1999 2002 2001 1999 1999\n"
     ]
    }
   ],
   "source": [
    "toprint = []\n",
    "for subid in shp.subm_id.unique():\n",
    "    s_loc = shp.loc[shp.subm_id == subid]\n",
    "    s = f\"Subm ID: {int(s_loc['subm_id'].iloc[0])}. N={len(s_loc)}.\"\n",
    "    for c in ['analysts', 'src_date']:\n",
    "        toprint = s_loc[c].unique()\n",
    "        if c != 'src_date':\n",
    "            s += ' ' + (str(toprint[0]))\n",
    "        else:\n",
    "            for d in toprint:\n",
    "                s += ' ' + d[:4]\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73a1078-af4d-4c8d-bb5f-e26ebc2b942f",
   "metadata": {},
   "source": [
    "Notes based on inidivual submission evaluations: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "491d23e6-03cb-4850-a1ae-1b3234583e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write out selection in intermediate shape files for manual GIS review\n",
    "# tmp_output_dir = mkdir(os.path.join(data_dir, 'l0_tmp_data', f'rgi{reg:02d}_inventories'))\n",
    "# tmp_output_dir_tar = mkdir(os.path.join(data_dir, 'l0_tmp_data'))\n",
    "# for subid in shp.subm_id.unique():\n",
    "#     s_loc = shp.loc[shp.subm_id == subid]\n",
    "#     s_loc.to_file(tmp_output_dir + f'/subm_{int(subid):03d}.shp')\n",
    "# print('Taring...')\n",
    "# print(subprocess.run(['tar', '-zcvf', f'{tmp_output_dir_tar}/rgi{reg:02d}_inventories.tar.gz', '-C', \n",
    "#                       os.path.join(data_dir, 'l0_tmp_data'), f'rgi{reg:02d}_inventories']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb0b05-a78d-43fb-ad3e-30d2fd189493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef25707-a61d-468f-ba7c-1e4b00beeae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f2fdc6-a538-45d9-b90e-dfb3fd0b8cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f05ef-e1cc-40cf-babe-c62fb132fb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "harmful-trust",
   "metadata": {},
   "source": [
    "## Apply selection criteria to reproduce RGI-6 for this region and check result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-convention",
   "metadata": {},
   "source": [
    "### Step 1: extract RGI6 from GLIMS data and do a check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...extract RGI06 from GLIMS based on 'geog_area'\n",
    "RGI_ss = shp.loc[shp['geog_area']=='Randolph Glacier Inventory; Umbrella RC for merging the RGI into GLIMS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-slovakia",
   "metadata": {},
   "source": [
    "#### load reference data (here RGI6) to enable comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to know the name of the file to open from zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile(rgi6_reg_file, \"r\") as z:\n",
    "    for f in z.filelist:\n",
    "        if '.shp' in f.filename:\n",
    "            fname = f.filename\n",
    "\n",
    "# load reference data\n",
    "ref_odf = gpd.read_file('zip://' + rgi6_reg_file + '/' + fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-spare",
   "metadata": {},
   "source": [
    "#### Number of elements (differences do not necessarily depict major problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of glaciers in new RGI subset:', len(RGI_ss))\n",
    "print('Number of glaciers in reference data:', len(ref_odf))\n",
    "print('Difference:', len(RGI_ss)-len(ref_odf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-console",
   "metadata": {},
   "source": [
    "#### check for dublicate glacier IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('number of glaciers without unique id in RGI06:', len(ref_odf)-len(ref_odf['GLIMSId'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('number of glaciers without unique id in RGI06 from GLIMS data base:', len(RGI_ss)-len(RGI_ss['glac_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "RGI_ss.loc[RGI_ss.glac_id.duplicated(keep=False)].plot(ec='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-reservoir",
   "metadata": {},
   "source": [
    "#### Check for 'nominal glaciers' in the RGI6 original data and delete them from new RGI subset from GLIMS if they are in there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many nominals in RGI06 (identifiable via 'Status' attribute in RGI 06)\n",
    "nom = ref_odf.loc[ref_odf.Status == 2]\n",
    "len(nom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nominal glaciers from new RGI subset\n",
    "RGI_ss = (RGI_ss.loc[~RGI_ss['glac_id'].isin(nom['GLIMSId'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-steps",
   "metadata": {},
   "source": [
    "#### Total area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an area field to RGI_ss and reference data\n",
    "RGI_ss['area'] = RGI_ss.to_crs({'proj':'cea'}).area\n",
    "ref_odf['area'] = ref_odf.to_crs({'proj':'cea'}).area\n",
    "nom['area'] = nom.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and compare area values\n",
    "Area_Rep = RGI_ss['area'].sum()/1000000\n",
    "print('Area Rep [km²]:', Area_Rep)\n",
    "Area_RGI6 = ref_odf['area'].sum()/1000000\n",
    "print('Area RGI6 [km²]:', Area_RGI6)\n",
    "Area_nom = nom['area'].sum()/1000000\n",
    "print('Area Nom [km²]:', Area_nom)\n",
    "d = (Area_Rep + Area_nom - Area_RGI6)\n",
    "d_perc = (d/Area_Rep*100)\n",
    "print('Area difference [km²]:',d,'/','percentage:', d_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-cache",
   "metadata": {},
   "source": [
    "## result of check (RGI from Glims global data base vs. RGI06 original):\n",
    "#### Problems: Nunataks in RGI-6 are not in GLIMS data, same is true for a number of divides for one glacier complex.\n",
    "#### number of glaciers differs by 8. 9 would be reasonable since this this the number of divides which has been added to the data-set for RGI-6.\n",
    "#### 1 dublicate ID in RGI-6 reproduced from GLIMS \n",
    "#### 0 nominal glaciers\n",
    "#### nevertheless 39 km² area difference... could result from a rather small number of (large) Nunataks not considered in the GLIMS data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-effort",
   "metadata": {},
   "source": [
    "## remaining tasks for RGI-7a:\n",
    "#### - check issues mentioned above\n",
    "#### - create data set of glaciers with edits in RGI-6 (few Nunataks & divides) to be ingested in GLIMS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-taylor",
   "metadata": {},
   "source": [
    "## Write out and tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "RGI_ss.to_file(dd + f'RGI{reg:02d}.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))## Write out and tar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-liechtenstein",
   "metadata": {},
   "source": [
    "## Find missing glaciers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import haversine\n",
    "import numpy as np\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_coord(geom):\n",
    "    \"\"\"To compute CenLon CenLat ourselves\"\"\"\n",
    "    x, y = geom.xy\n",
    "    return x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = ref_odf.copy()\n",
    "rgi7 = RGI_ss.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CenLon CenLat ourselves\n",
    "rp = df_ref.representative_point()\n",
    "\n",
    "coordinates = np.array(list(rp.apply(xy_coord)))\n",
    "df_ref['CenLon'] = coordinates[:, 0]\n",
    "df_ref['CenLat'] = coordinates[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_orig = df_ref.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all RGI7 glaciers and find their equivalent in ref\n",
    "df_ref = df_ref_orig.copy()\n",
    "not_found = {}\n",
    "to_drop = []\n",
    "for i, (ref_area, lon, lat) in progressbar.progressbar(enumerate(zip(rgi7['area'].values, rgi7.CenLon.values, rgi7.CenLat.values)), max_value=len(rgi7)):\n",
    "#     dist = haversine(lon, lat, df_ref.CenLon.values, df_ref.CenLat.values)\n",
    "    dist = (lon - df_ref.CenLon.values)**2 + (lat - df_ref.CenLat.values)**2 \n",
    "    found = False\n",
    "    for j in np.argsort(dist)[:10]:\n",
    "        s6 = df_ref.iloc[j]\n",
    "        if np.allclose(s6['area'], ref_area, rtol=0.001):\n",
    "            found = True\n",
    "            to_drop.append(s6.name)\n",
    "            break\n",
    "    if not found:\n",
    "        not_found[i] = df_ref.iloc[np.argsort(dist)[:10]]\n",
    "    if len(to_drop) > 1000:\n",
    "        df_ref.drop(labels=to_drop, inplace=True)\n",
    "        to_drop = []\n",
    "df_ref.drop(labels=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(not_found), len(df_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_rgi7 = rgi7.iloc[list(not_found.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-therapist",
   "metadata": {},
   "source": [
    "Here the problems are different - the outlines are often close, but not exactly same. To be reevaluated when Will's data are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_rgi7.plot(edgecolor='k');\n",
    "plt.title('GLIMS');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.plot(edgecolor='k');\n",
    "plt.title('RGI6');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_problem_glaciers'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_problem_glaciers_tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "pb_rgi7.to_file(dd + f'RGI{reg:02d}_glims.shp')\n",
    "df_ref.to_file(dd + f'RGI{reg:02d}_ref.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-plastic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
