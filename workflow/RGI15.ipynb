{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dynamic-portfolio",
   "metadata": {},
   "source": [
    "# RGI-07: Region 15\n",
    "\n",
    "F. Maussion & S. Galos, June 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from utils import mkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-shirt",
   "metadata": {},
   "source": [
    "### specify RGI-region and storage paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of interest\n",
    "reg = 15\n",
    "\n",
    "# go down from rgi7_scripts/workflow\n",
    "data_dir = '../../rgi7_data/'\n",
    "\n",
    "# Level 2 GLIMS files\n",
    "l2_dir = os.path.join(data_dir, 'l2_sel_reg_tars')\n",
    "\n",
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_rgi7a'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_rgi7a_tar'))\n",
    "\n",
    "# RGI v6 file for comparison later \n",
    "rgi6_reg_file = os.path.join(data_dir, 'l0_RGIv6', '15_rgi60_SouthAsiaEast.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region is based on GAMDAM, use for comparison\n",
    "support_dir = os.path.join(data_dir, 'l0_support_data')\n",
    "gamdam_dir = os.path.join(support_dir, 'gamdam')\n",
    "\n",
    "# Region file to select from gamdam\n",
    "reg_file = os.path.join(data_dir, 'l0_regions', '00_rgi70_regions', '00_rgi70_O1Regions.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-plant",
   "metadata": {},
   "source": [
    "### Load the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read L2 files\n",
    "shp = gpd.read_file('tar://' + l2_dir + f'/RGI{reg:02d}.tar.gz/RGI{reg:02d}/RGI{reg:02d}.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-sacramento",
   "metadata": {},
   "source": [
    "### Apply selection criteria to create the RGI-07 data subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to get the data relevant for RGI07 and select by attributes\n",
    "rgi7 = shp.loc[shp['analysts'] == 'Sakai, Akiko']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-sacramento",
   "metadata": {},
   "source": [
    "## Write out and tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "rgi7.to_file(dd + f'RGI{reg:02d}.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-likelihood",
   "metadata": {},
   "source": [
    "## New RGI-file created - Check result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-dallas",
   "metadata": {},
   "source": [
    "### load reference data (here GAMDAM original) to enable comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify path to reference data set\n",
    "import zipfile\n",
    "import glob\n",
    "gam_files = glob.glob(gamdam_dir + '/*.zip')\n",
    "df_ref = []\n",
    "for gf in gam_files:\n",
    "    # Just to know the name of the file to open from zip\n",
    "    with zipfile.ZipFile(gf, \"r\") as z:\n",
    "        for f in z.filelist:\n",
    "            if '.shp' in f.filename:\n",
    "                fname = f.filename\n",
    "    df_ref.append(gpd.read_file('zip://' + gf + '/' + fname))\n",
    "\n",
    "df_ref = pd.concat(df_ref).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate representative points for reference data\n",
    "ref_rp = df_ref.representative_point()\n",
    "\n",
    "# Make a dataframe out of it and add the original index to recover it later\n",
    "ref_rp = ref_rp.to_frame('geometry')\n",
    "ref_rp['orig_index'] = df_ref.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read region file\n",
    "reg_f = gpd.read_file(reg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the overlay with the RGI region of interest -> get the rep. points which are located inside the region boundaries\n",
    "ref_intersect = gpd.overlay(ref_rp, reg_f.loc[reg_f.RGI_CODE == f'{reg:02d}'], how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now select the entries which intersect from the original shape file (-> extract the polygons) \n",
    "df_ref = df_ref.loc[ref_intersect['orig_index'].values].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-organic",
   "metadata": {},
   "source": [
    "## Compare new RGI-file and reference data set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-constitutional",
   "metadata": {},
   "source": [
    "### Number of elements (differences do not necessarily depict major problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of glaciers in new RGI subset:', len(rgi7))\n",
    "print('Number of glaciers in reference data:', len(df_ref))\n",
    "print('Difference:', len(rgi7)-len(df_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-cookie",
   "metadata": {},
   "source": [
    "### Total area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an area field to the selected GAMDAM table\n",
    "df_ref['area'] = df_ref.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and compare area values\n",
    "Area_RGI = rgi7['area'].sum() * 1e-6\n",
    "print('Area RGI [km²]:', Area_RGI)\n",
    "Area_ref = df_ref['area'].sum() * 1e-6\n",
    "print('Area Ref [km²]:', Area_ref)\n",
    "d = (Area_RGI - Area_ref)\n",
    "print('Area difference [km²]:',d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-rabbit",
   "metadata": {},
   "source": [
    "**We believe that remaining errors are of the same type as Region 01: multipolygons that weren't properly ingested in GLIMS.** We will check this below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-rental",
   "metadata": {},
   "source": [
    "### Comparison with RGI6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to know the name of the file to open from zip\n",
    "import zipfile\n",
    "with zipfile.ZipFile(rgi6_reg_file, \"r\") as z:\n",
    "    for f in z.filelist:\n",
    "        if '.shp' in f.filename:\n",
    "            fname = f.filename\n",
    "\n",
    "# load reference data\n",
    "rgi6 = gpd.read_file('zip://' + rgi6_reg_file + '/' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of glaciers in new RGI subset:', len(rgi7))\n",
    "print('Number of glaciers in RGI6 data:', len(rgi6))\n",
    "print('Difference:', len(rgi7)-len(rgi6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi6['area'] = rgi6.to_crs({'proj':'cea'}).area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and compare area values\n",
    "Area_RGI = rgi7['area'].sum() * 1e-6\n",
    "print('Area RGI7 [km²]:', Area_RGI)\n",
    "Area_ref = rgi6['area'].sum() * 1e-6\n",
    "print('Area RGI6 [km²]:', Area_ref)\n",
    "d = (Area_RGI - Area_ref)\n",
    "print('Area difference [km²]:',d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-consultancy",
   "metadata": {},
   "source": [
    "# End of revised notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-deficit",
   "metadata": {},
   "source": [
    "## Find missing glaciers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import haversine\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_coord(geom):\n",
    "    \"\"\"To compute CenLon CenLat ourselves\"\"\"\n",
    "    x, y = geom.xy\n",
    "    return x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CenLon CenLat ourselves\n",
    "rp = df_ref.representative_point()\n",
    "\n",
    "coordinates = np.array(list(rp.apply(xy_coord)))\n",
    "df_ref['CenLon'] = coordinates[:, 0]\n",
    "df_ref['CenLat'] = coordinates[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_orig = df_ref.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all RGI7 glaciers and find their equivalent in ref\n",
    "df_ref = df_ref_orig.copy()\n",
    "not_found = {}\n",
    "to_drop = []\n",
    "for i, (ref_area, lon, lat) in progressbar.progressbar(enumerate(zip(rgi7['area'].values, rgi7.CenLon.values, rgi7.CenLat.values)), max_value=len(rgi7)):\n",
    "#     dist = haversine(lon, lat, df_ref.CenLon.values, df_ref.CenLat.values)\n",
    "    dist = (lon - df_ref.CenLon.values)**2 + (lat - df_ref.CenLat.values)**2 \n",
    "    found = False\n",
    "    for j in np.argsort(dist)[:10]:\n",
    "        s6 = df_ref.iloc[j]\n",
    "        if np.allclose(s6['area'], ref_area, rtol=0.001):\n",
    "            found = True\n",
    "            to_drop.append(s6.name)\n",
    "            break\n",
    "    if not found:\n",
    "        not_found[i] = df_ref.iloc[np.argsort(dist)[:10]]\n",
    "    if len(to_drop) > 1000:\n",
    "        df_ref.drop(labels=to_drop, inplace=True)\n",
    "        to_drop = []\n",
    "df_ref.drop(labels=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(not_found), len(df_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(not_found.keys()):\n",
    "    ax = rgi7.iloc[[k]].plot(edgecolor='k');\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_rgi7 = rgi7.iloc[list(not_found.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories\n",
    "output_dir = mkdir(os.path.join(data_dir, 'l3_problem_glaciers'))\n",
    "output_dir_tar = mkdir(os.path.join(data_dir, 'l3_problem_glaciers_tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = mkdir(f'{output_dir}/RGI{reg:02d}/', reset=True)\n",
    "\n",
    "print('Writing...')\n",
    "pb_rgi7.to_file(dd + f'RGI{reg:02d}_glims.shp')\n",
    "df_ref.to_file(dd + f'RGI{reg:02d}_ref.shp')\n",
    "\n",
    "print('Taring...')\n",
    "print(subprocess.run(['tar', '-zcvf', f'{output_dir_tar}/RGI{reg:02d}.tar.gz', '-C', output_dir, f'RGI{reg:02d}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-jesus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
